/**
 * Traversal Coverage Diagnostic Test
 * 
 * Verifies that the working set architecture achieves >90% message coverage
 * before recycling begins. This test proves that the persistent working set
 * fixes the traversal coverage problem.
 * 
 * BEFORE fix (original diagnostic):
 * - Coverage: 13/2454 = 0.5% (only 13 unique focus before recycling)
 * - Reason: Fresh batches overlapped, same messages repeated
 * 
 * AFTER fix (this test should show):
 * - Coverage: >1800/2000 = >90% (most messages seen before recycling)
 * - Reason: Persistent working set ensures systematic traversal
 */

import { describe, it, expect, beforeEach, afterEach } from 'vitest'
import { MessageLogicService } from '@/lib/services/message-logic-service'
import type { MessagePoolConfig } from '@/types/grief-messages'
import { createTestMessages } from '../mocks/database-service'
import { createMockSupabaseClient, type MockSupabaseClient } from '../mocks/supabase-client'
import { DEFAULT_CONFIG } from '@/lib/config/message-pool-config'

describe('Traversal Coverage (Diagnostic)', () => {
  let service: MessageLogicService
  let mockClient: MockSupabaseClient
  let config: MessagePoolConfig

  beforeEach(() => {
    config = {
      ...DEFAULT_CONFIG,
      workingSetSize: 400,
      clusterSize: 20,
      pollingInterval: 100 // Fast polling for tests
    }
    mockClient = createMockSupabaseClient()
  })

  afterEach(() => {
    if (service) {
      service.cleanup()
    }
  })

  it('should achieve full database coverage and high working set efficiency', async () => {
    console.log('\nüîç DIAGNOSTIC: Coverage Metrics\n')
    
    // Setup: Create large message pool (2000 messages)
    const totalMessages = 2000
    const messages = createTestMessages(totalMessages)
    mockClient.setMessages(messages)
    
    console.log(`üìä Test Setup:`)
    console.log(`   Total messages in database: ${totalMessages}`)
    console.log(`   Working set size: ${config.workingSetSize}`)
    console.log(`   Cluster size: ${config.clusterSize}`)
    console.log()
    
    // Track THREE different sets of message IDs
    const messagesEnteredWorkingSet = new Set<string>()
    const messagesSeenInClusters = new Set<string>()
    let recyclingDetected = false
    let clusterCount = 0
    const maxClusters = 500
    
    // Initialize service with realistic config
    service = new MessageLogicService(mockClient as any, config)
    
    // Track messages entering working set via callback - MUST be registered before initialize()
    service.onWorkingSetChange(({ added }) => {
      added.forEach(msg => messagesEnteredWorkingSet.add(msg.id))
    })
    
    await service.initialize()
    
    const stats = service.getStats()
    console.log(`‚úÖ Service initialized`)
    console.log(`   Initial working set: ${stats.workingSetSize}`)
    console.log()
    
    console.log(`üéØ Generating clusters until recycling detected...`)
    console.log()
    
    // Generate clusters until we detect recycling
    while (clusterCount < maxClusters && !recyclingDetected) {
      const cluster = await service.getNextCluster()
      
      if (!cluster) {
        console.log(`   ‚ùå Cluster generation returned null at cluster ${clusterCount}`)
        break
      }
      
      // Track ALL IDs seen in clusters (focus + related)
      messagesSeenInClusters.add(cluster.focusId)
      cluster.related.forEach(r => messagesSeenInClusters.add(r.messageId))
      
      clusterCount++
      
      // Check for recycling by watching cursor
      const currentStats = service.getStats()
      // We can't easily detect recycling in mock, so just run until we've covered enough
      // In real Supabase tests, we'd watch the cursor jump
      
      // Log progress periodically
      if (clusterCount % 25 === 0) {
        const enteredPct = (messagesEnteredWorkingSet.size / totalMessages) * 100
        const seenPct = (messagesSeenInClusters.size / totalMessages) * 100
        console.log(`   Cluster ${clusterCount}:`)
        console.log(`      Entered working set: ${messagesEnteredWorkingSet.size} (${enteredPct.toFixed(1)}%)`)
        console.log(`      Seen in clusters: ${messagesSeenInClusters.size} (${seenPct.toFixed(1)}%)`)
      }
    }
    
    console.log()
    console.log(`üìà Results:`)
    console.log(`   Clusters generated: ${clusterCount}`)
    console.log(`   Messages in database: ${totalMessages}`)
    console.log(`   Messages entered working set: ${messagesEnteredWorkingSet.size}`)
    console.log(`   Messages seen in clusters: ${messagesSeenInClusters.size}`)
    
    // Calculate BOTH metrics
    const metric1 = (messagesSeenInClusters.size / messagesEnteredWorkingSet.size) * 100
    const metric2 = (messagesEnteredWorkingSet.size / totalMessages) * 100
    
    console.log()
    console.log(`‚ú® METRIC 1 - Working Set Efficiency:`)
    console.log(`   ${messagesSeenInClusters.size} seen / ${messagesEnteredWorkingSet.size} entered = ${metric1.toFixed(1)}%`)
    console.log(`   (Measures: Are messages that enter the working set actually being shown?)`)
    console.log()
    console.log(`‚ú® METRIC 2 - Database Coverage:`)
    console.log(`   ${messagesEnteredWorkingSet.size} entered / ${totalMessages} in database = ${metric2.toFixed(1)}%`)
    console.log(`   (Measures: Does the cursor cycle through the entire database?)`)
    console.log()
    
    // ASSERTION 1: Working set efficiency should be very high (>95%)
    // Almost every message that enters working set should eventually be seen
    expect(metric1).toBeGreaterThan(95)
    
    // ASSERTION 2: Database coverage should be 100%
    // All messages should enter working set via cursor recycling
    expect(metric2).toBe(100)
    
    // ASSERTION 3: Should see most messages in clusters
    expect(messagesSeenInClusters.size).toBeGreaterThan(totalMessages * 0.95)
    
    console.log(`‚úÖ All assertions passed!`)
    console.log(`   ‚úì Working set efficiency: ${metric1.toFixed(1)}% (target >95%)`)
    console.log(`   ‚úì Database coverage: ${metric2.toFixed(1)}% (target 100%)`)
    console.log(`   ‚úì Messages seen: ${messagesSeenInClusters.size}/${totalMessages}`)
    console.log()
    
  }, 120000) // 120 second timeout for large test

  it('should track all messages in related positions (not just focus)', async () => {
    console.log('\nüîç DIAGNOSTIC: Full Message Coverage (All Positions)\n')
    
    // Create smaller message pool for this test
    const totalMessages = 500
    const messages = createTestMessages(totalMessages)
    mockClient.setMessages(messages)
    
    console.log(`üìä Test Setup:`)
    console.log(`   Total messages: ${totalMessages}`)
    console.log(`   Tracking messages in ALL positions (focus + related)`)
    console.log()
    
    service = new MessageLogicService(mockClient as any, config)
    await service.initialize()
    
    // Track ALL message IDs seen in ANY position
    const seenAllIds = new Set<string>()
    const seenFocusIds = new Set<string>()
    let recyclingDetected = false
    let clusterCount = 0
    const maxClusters = 300
    
    console.log(`üéØ Generating clusters...`)
    console.log()
    
    while (clusterCount < maxClusters && !recyclingDetected) {
      const cluster = await service.getNextCluster()
      
      if (!cluster) break
      
      // Track focus ID
      if (seenFocusIds.has(cluster.focusId)) {
        recyclingDetected = true
        break
      }
      seenFocusIds.add(cluster.focusId)
      
      // Track ALL IDs (focus + related)
      seenAllIds.add(cluster.focusId)
      cluster.related.forEach(r => seenAllIds.add(r.messageId))
      
      clusterCount++
      
      if (clusterCount % 25 === 0) {
        const allCoverage = (seenAllIds.size / totalMessages) * 100
        console.log(`   Cluster ${clusterCount}: ${seenAllIds.size} total unique IDs (${allCoverage.toFixed(1)}% coverage)`)
      }
    }
    
    console.log()
    console.log(`üìà Results:`)
    console.log(`   Clusters generated: ${clusterCount}`)
    console.log(`   Unique focus IDs: ${seenFocusIds.size}`)
    console.log(`   Total unique IDs (all positions): ${seenAllIds.size}`)
    console.log(`   Total messages: ${totalMessages}`)
    
    const focusCoverage = (seenFocusIds.size / totalMessages) * 100
    const allCoverage = (seenAllIds.size / totalMessages) * 100
    
    console.log()
    console.log(`‚ú® FOCUS COVERAGE: ${seenFocusIds.size}/${totalMessages} = ${focusCoverage.toFixed(1)}%`)
    console.log(`‚ú® ALL COVERAGE: ${seenAllIds.size}/${totalMessages} = ${allCoverage.toFixed(1)}%`)
    console.log()
    
    // ASSERTION: Coverage will be lower than before due to filtering currently-displayed messages
    // This is CORRECT - we prevent recycling by excluding ~18 messages per cycle
    // Expected coverage: 75-85% (down from 95%+ with broken recycling behavior)
    expect(allCoverage).toBeGreaterThan(75)
    
    // ASSERTION: All coverage should be higher than focus coverage
    expect(seenAllIds.size).toBeGreaterThan(seenFocusIds.size)
    
    console.log(`‚úÖ All assertions passed!`)
    console.log(`   ‚úì All positions coverage >95%: ${allCoverage.toFixed(1)}%`)
    console.log(`   ‚úì All coverage > focus coverage: ${seenAllIds.size} > ${seenFocusIds.size}`)
    console.log()
    
  }, 90000)

  it('should make priority messages visible quickly', async () => {
    console.log('\nüîç DIAGNOSTIC: Priority Message Visibility\n')
    
    const totalMessages = 1000
    const messages = createTestMessages(totalMessages)
    mockClient.setMessages(messages)
    
    console.log(`üìä Test Setup:`)
    console.log(`   Initial messages: ${totalMessages}`)
    console.log(`   Will inject priority messages during traversal`)
    console.log()
    
    // Track priority message lifecycle
    const priorityIds = new Set<string>()
    const idsEnteredWorkingSet = new Set<string>()
    const idsSeenInClusters = new Set<string>()
    const firstAppearance = new Map<string, number>() // message ID -> cluster number
    
    service = new MessageLogicService(mockClient as any, config)
    
    // Listen for working set changes to track when priority messages enter - MUST be before initialize()
    service.onWorkingSetChange(({ added }) => {
      const priorityInBatch = added.filter(msg => priorityIds.has(msg.id))
      if (priorityInBatch.length > 0) {
        console.log(`   [CALLBACK] Working set change: ${added.length} added, ${priorityInBatch.length} are priority: ${priorityInBatch.map(m => m.id).join(', ')}`)
      }
      added.forEach(msg => {
        if (priorityIds.has(msg.id)) {
          idsEnteredWorkingSet.add(msg.id)
        }
      })
    })
    
    await service.initialize()
    
    let clusterCount = 0
    let priorityMessagesAdded = 0
    const maxClusters = 100
    const priorityInterval = 5 // Add priority message every 5 clusters
    
    console.log(`üéØ Generating clusters with priority injection...`)
    console.log()
    
    for (let i = 0; i < maxClusters; i++) {
      const cluster = await service.getNextCluster()
      
      if (!cluster) break
      
      clusterCount++
      
      // Check if any priority messages appear in this cluster
      if (priorityIds.has(cluster.focusId)) {
        if (!idsSeenInClusters.has(cluster.focusId)) {
          idsSeenInClusters.add(cluster.focusId)
          firstAppearance.set(cluster.focusId, clusterCount)
        }
      }
      
      cluster.related.forEach(r => {
        if (priorityIds.has(r.messageId)) {
          if (!idsSeenInClusters.has(r.messageId)) {
            idsSeenInClusters.add(r.messageId)
            firstAppearance.set(r.messageId, clusterCount)
          }
        }
      })
      
      // Inject priority messages periodically
      if (clusterCount % priorityInterval === 0 && priorityMessagesAdded < 20) {
        const newMsg = {
          content: `Priority message ${priorityMessagesAdded + 1}`,
          approved: true,
          created_at: new Date().toISOString(),
          deleted_at: null
        }
        
        const inserted = await service.addNewMessage(newMsg)
        if (inserted) {
          priorityIds.add(inserted.id)
          priorityMessagesAdded++
          console.log(`   Submitted priority message ${priorityMessagesAdded} (ID: ${inserted.id}) at cluster ${clusterCount}. Total in set: ${priorityIds.size}`)
        }
      }
    }
    
    // Generate a few more clusters to drain the priority queue
    console.log(`   Draining priority queue...`)
    for (let i = 0; i < 5; i++) {
      const cluster = await service.getNextCluster()
      if (!cluster) break
      
      clusterCount++
      
      // Check if any priority messages appear
      if (priorityIds.has(cluster.focusId)) {
        if (!idsSeenInClusters.has(cluster.focusId)) {
          idsSeenInClusters.add(cluster.focusId)
          firstAppearance.set(cluster.focusId, clusterCount)
        }
      }
      
      cluster.related.forEach(r => {
        if (priorityIds.has(r.messageId)) {
          if (!idsSeenInClusters.has(r.messageId)) {
            idsSeenInClusters.add(r.messageId)
            firstAppearance.set(r.messageId, clusterCount)
          }
        }
      })
    }
    
    console.log()
    console.log(`üìà Results:`)
    console.log(`   Priority messages submitted: ${priorityMessagesAdded}`)
    console.log(`   Entered working set: ${idsEnteredWorkingSet.size}`)
    console.log(`   Appeared in clusters: ${idsSeenInClusters.size}`)
    console.log()
    
    // DEBUG OUTPUT
    console.log(`üîç DEBUG:`)
    console.log(`   Priority IDs submitted: ${Array.from(priorityIds).slice(0, 5).join(', ')}${priorityIds.size > 5 ? '...' : ''}`)
    console.log(`   IDs entered working set: ${Array.from(idsEnteredWorkingSet).join(', ')}`)
    console.log(`   IDs seen in clusters: ${Array.from(idsSeenInClusters).slice(0, 5).join(', ')}${idsSeenInClusters.size > 5 ? '...' : ''}`)
    console.log()
    
    // Calculate appearance times
    const appearanceTimes: number[] = []
    firstAppearance.forEach((clusterNum, msgId) => {
      // Find when it was submitted (rough estimate based on priority message number)
      const msgNumber = parseInt(msgId.match(/\d+/)?.[0] || '0')
      const submittedAtCluster = msgNumber * priorityInterval
      const clustersUntilAppearance = clusterNum - submittedAtCluster
      appearanceTimes.push(clustersUntilAppearance)
    })
    
    if (appearanceTimes.length > 0) {
      const avgAppearanceTime = appearanceTimes.reduce((a, b) => a + b, 0) / appearanceTimes.length
      const maxAppearanceTime = Math.max(...appearanceTimes)
      console.log(`‚è±Ô∏è  Appearance Times:`)
      console.log(`   Average clusters until visible: ${avgAppearanceTime.toFixed(1)}`)
      console.log(`   Maximum clusters until visible: ${maxAppearanceTime}`)
      console.log()
    }
    
    // ASSERTION 1: All priority messages should enter working set
    expect(idsEnteredWorkingSet.size).toBe(priorityMessagesAdded)
    
    // ASSERTION 2: All priority messages should appear in clusters
    // (Allow for some to not appear yet if submitted very late)
    const visibilityRate = idsSeenInClusters.size / priorityMessagesAdded
    expect(visibilityRate).toBeGreaterThan(0.8) // At least 80% should be visible
    
    // ASSERTION 3: Priority messages should appear quickly (within 5 clusters)
    if (appearanceTimes.length > 0) {
      const avgAppearanceTime = appearanceTimes.reduce((a, b) => a + b, 0) / appearanceTimes.length
      expect(avgAppearanceTime).toBeLessThan(5)
    }
    
    console.log(`‚úÖ All assertions passed!`)
    console.log(`   ‚úì All priority messages entered working set`)
    console.log(`   ‚úì ${(visibilityRate * 100).toFixed(0)}% became visible in clusters`)
    console.log()
    
  }, 120000)

  it('should maintain working set size within acceptable range', async () => {
    console.log('\nüîç DIAGNOSTIC: Working Set Size Stability\n')
    
    const totalMessages = 1000
    const messages = createTestMessages(totalMessages)
    mockClient.setMessages(messages)
    
    console.log(`üìä Test Setup:`)
    console.log(`   Total messages: ${totalMessages}`)
    console.log(`   Target working set size: ${config.workingSetSize}`)
    console.log(`   Acceptable range: ${Math.floor(config.workingSetSize * 0.9)}-${Math.ceil(config.workingSetSize * 1.1)} (90-110%)`)
    console.log()
    
    service = new MessageLogicService(mockClient as any, config)
    await service.initialize()
    
    const targetSize = config.workingSetSize
    const minAcceptable = Math.floor(targetSize * 0.9)
    const maxAcceptable = Math.ceil(targetSize * 1.1)
    const workingSetSizes: number[] = []
    let clusterCount = 0
    const maxClusters = 100
    
    console.log(`üéØ Checking working set size across clusters...`)
    console.log()
    
    // Record initial size
    workingSetSizes.push(service.getWorkingSetSize())
    
    for (let i = 0; i < maxClusters; i++) {
      const cluster = await service.getNextCluster()
      if (!cluster) break
      
      clusterCount++
      const size = service.getWorkingSetSize()
      workingSetSizes.push(size)
      
      if (i % 20 === 0) {
        console.log(`   Cluster ${clusterCount}: Working set size = ${size}`)
      }
    }
    
    console.log()
    console.log(`üìà Results:`)
    console.log(`   Clusters generated: ${clusterCount}`)
    console.log(`   Working set size samples: ${workingSetSizes.length}`)
    console.log(`   Target size: ${targetSize}`)
    console.log(`   Acceptable range: ${minAcceptable}-${maxAcceptable}`)
    
    // Calculate stats
    const allInRange = workingSetSizes.every(size => size >= minAcceptable && size <= maxAcceptable)
    const minSize = Math.min(...workingSetSizes)
    const maxSize = Math.max(...workingSetSizes)
    const avgSize = workingSetSizes.reduce((a, b) => a + b, 0) / workingSetSizes.length
    
    console.log(`   Min size: ${minSize}`)
    console.log(`   Max size: ${maxSize}`)
    console.log(`   Avg size: ${avgSize.toFixed(1)}`)
    console.log(`   All samples in range: ${allInRange}`)
    console.log()
    
    // ASSERTION: All samples should be within acceptable range (90-110%)
    expect(allInRange).toBe(true)
    
    // ASSERTION: Min and max should both be within acceptable range
    expect(minSize).toBeGreaterThanOrEqual(minAcceptable)
    expect(maxSize).toBeLessThanOrEqual(maxAcceptable)
    
    // ASSERTION: Average should be close to target (within 5%)
    expect(avgSize).toBeGreaterThan(targetSize * 0.95)
    expect(avgSize).toBeLessThan(targetSize * 1.05)
    
    console.log(`‚úÖ All assertions passed!`)
    console.log(`   ‚úì Working set size stable within ${minAcceptable}-${maxAcceptable} across ${workingSetSizes.length} samples`)
    console.log(`   ‚úì Average size ${avgSize.toFixed(1)} within 5% of target ${targetSize}`)
    console.log()
    
  }, 90000)


})
